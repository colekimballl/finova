'''
2025 NOTE:
THE MAX BARS OF DATA YOU CAN GET FROM HYPERLIQUID IS 5000
IF YOU NEED MORE USE THE COINBASE SCRIPT
NO MATTER WHAT THE VIDEO SAYS, ABOVE IS THE MOST UPDATED 
'''
Ôªø
Ôªø
import pandas as pd
import requests
from datetime import datetime, timedelta
import numpy as np
import time
Ôªø
# Define symbol and timeframe
symbol = 'WIF'
timeframe = '15m'
Ôªø
# Constants
BATCH_SIZE = 5000 # MAX IS 5000 FOR HYPERLIQUID IF YOU NEED MORE USE COINBASE
MAX_RETRIES = 3
MAX_ROWS = 5000  # New constant to limit the number of rows
Ôªø
# Global variable to store timestamp offset
timestamp_offset = None
Ôªø
def adjust_timestamp(dt):
    """Adjust API timestamps by subtracting the timestamp offset."""
    if timestamp_offset is not None:
        corrected_dt = dt - timestamp_offset
        return corrected_dt
    else:
        return dt  # No adjustment needed if offset is not set
Ôªø
def get_ohlcv2(symbol, interval, start_time, end_time, batch_size=BATCH_SIZE):
    global timestamp_offset
    print(f'\nüîç Requesting data:')
    print(f'üìä Batch Size: {batch_size}')
    print(f'üöÄ Start: {start_time.strftime("%Y-%m-%d %H:%M:%S")} UTC')
    print(f'üéØ End: {end_time.strftime("%Y-%m-%d %H:%M:%S")} UTC')
Ôªø
    start_ts = int(start_time.timestamp() * 1000)
    end_ts = int(end_time.timestamp() * 1000)
Ôªø
    for attempt in range(MAX_RETRIES):
        try:
            response = requests.post(
                'https://api.hyperliquid.xyz/info',
                headers={'Content-Type': 'application/json'},
                json={
                    "type": "candleSnapshot",
                    "req": {
                        "coin": symbol,
                        "interval": interval,
                        "startTime": start_ts,
                        "endTime": end_ts,
                        "limit": batch_size
                    }
                },
                timeout=10
            )
Ôªø
            if response.status_code == 200:
                snapshot_data = response.json()
                if snapshot_data:
                    # Manually calculate timestamp offset if not already done
                    if timestamp_offset is None:
                        latest_api_timestamp = datetime.utcfromtimestamp(snapshot_data[-1]['t'] / 1000)
                        # Your system's current date (adjust to your actual current date)
                        system_current_date = datetime.utcnow()
                        # Manually set the expected latest timestamp (e.g., now)
                        expected_latest_timestamp = system_current_date
                        # Calculate offset
                        timestamp_offset = latest_api_timestamp - expected_latest_timestamp
                        print(f"‚è±Ô∏è Calculated timestamp offset: {timestamp_offset}")
                    # Adjust timestamps due to API bug
                    for candle in snapshot_data:
                        dt = datetime.utcfromtimestamp(candle['t'] / 1000)
                        # Adjust date
                        adjusted_dt = adjust_timestamp(dt)
                        candle['t'] = int(adjusted_dt.timestamp() * 1000)
                    first_time = datetime.utcfromtimestamp(snapshot_data[0]['t'] / 1000)
                    last_time = datetime.utcfromtimestamp(snapshot_data[-1]['t'] / 1000)
                    print(f'‚ú® Received {len(snapshot_data)} candles')
                    print(f'üìà First: {first_time}')
                    print(f'üìâ Last: {last_time}')
                    return snapshot_data
                else:
                    print('‚ùå No data returned by API')
                    return None
            else:
                print(f'‚ö†Ô∏è HTTP Error {response.status_code}: {response.text}')
        except requests.exceptions.RequestException as e:
            print(f'‚ö†Ô∏è Request failed (attempt {attempt + 1}): {e}')
            time.sleep(1)
    return None
Ôªø
def process_data_to_df(snapshot_data):
    if snapshot_data:
        columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
        data = []
        for snapshot in snapshot_data:
            timestamp = datetime.utcfromtimestamp(snapshot['t'] / 1000)
            open_price = snapshot['o']
            high_price = snapshot['h']
            low_price = snapshot['l']
            close_price = snapshot['c']
            volume = snapshot['v']
            data.append([timestamp, open_price, high_price, low_price, close_price, volume])
Ôªø
        df = pd.DataFrame(data, columns=columns)
        return df
    else:
        return pd.DataFrame()
Ôªø
def fetch_historical_data(symbol, timeframe):
    """Fetch 5000 rows of historical data."""
    print("\nüåô MoonDev's Historical Data Fetcher")
    print(f"üéØ Symbol: {symbol}")
    print(f"‚è∞ Timeframe: {timeframe}")
Ôªø
    # Just fetch the most recent 5000 candles
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(days=60)  # Setting a wide enough window
Ôªø
    print("\nüîÑ Fetching data:")
    print(f"üìÖ From: {start_time.strftime('%Y-%m-%d %H:%M:%S')} UTC")
    print(f"üìÖ To: {end_time.strftime('%Y-%m-%d %H:%M:%S')} UTC")
Ôªø
    data = get_ohlcv2(symbol, timeframe, start_time, end_time, batch_size=5000)
    
    if not data:
        print("‚ùå No data available.")
        return pd.DataFrame()
Ôªø
    df = process_data_to_df(data)
Ôªø
    if not df.empty:
        # Sort by timestamp and take the most recent 5000 rows
        df = df.sort_values('timestamp', ascending=False).head(5000).sort_values('timestamp')
        df = df.reset_index(drop=True)
Ôªø
        print("\nüìä Final data summary:")
        print(f"üìà Total candles: {len(df)}")
        print(f"üìÖ Date range: {df['timestamp'].min()} to {df['timestamp'].max()}")
        print("‚ú® Thanks for using MoonDev's Data Fetcher! ‚ú®")
Ôªø
    return df
Ôªø
# Use the function
all_data = fetch_historical_data(symbol, timeframe)
Ôªø
# Save the data
if not all_data.empty:
    timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
    file_path = f'data/{symbol}_{timeframe}_{timestamp}_historical.csv'
    all_data.to_csv(file_path, index=False)
    print(f'\nüíæ Data saved to {file_path}')
else:
    print('‚ùå No data to save.')

